{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jRUBmnGJgZPk",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:14:46.186526Z",
     "start_time": "2024-01-25T11:14:46.174851900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_excel(\"Sample_Files/houses_for_rent_madrid.xlsx\")"
   ],
   "metadata": {
    "id": "VELH01BvgqnT",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:14:49.998531800Z",
     "start_time": "2024-01-25T11:14:49.391959800Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data.dtypes"
   ],
   "metadata": {
    "id": "x-7dBXFbgxd9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "89f02351-2340-474e-bb56-5617ebf161cd",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:14:51.143649900Z",
     "start_time": "2024-01-25T11:14:51.112334900Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Id                int64\nDistrict         object\nAddress          object\nNumber           object\nArea             object\nRent              int64\nBedrooms        float64\nSq.Mt             int64\nFloor           float64\nOuter           float64\nElevator        float64\nPenthouse         int64\nCottage           int64\nDuplex            int64\nSemidetached      int64\ndtype: object"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data.describe(include='all')"
   ],
   "metadata": {
    "id": "PSkvDhOzg5Jp",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "outputId": "b782ab28-123f-4a87-926f-ce5045e61924",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:14:53.548491900Z",
     "start_time": "2024-01-25T11:14:53.500972200Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Id   District            Address Number       Area  \\\ncount   2089.000000       2089               2089    747       2085   \nunique          NaN         20               1336    137        140   \ntop             NaN  Salamanca  Piso en Recoletos      1  Recoletos   \nfreq            NaN        313                 25     29         93   \nmean    1094.026807        NaN                NaN    NaN        NaN   \nstd      630.612544        NaN                NaN    NaN        NaN   \nmin        1.000000        NaN                NaN    NaN        NaN   \n25%      550.000000        NaN                NaN    NaN        NaN   \n50%     1094.000000        NaN                NaN    NaN        NaN   \n75%     1636.000000        NaN                NaN    NaN        NaN   \nmax     2188.000000        NaN                NaN    NaN        NaN   \n\n                Rent     Bedrooms        Sq.Mt         Floor        Outer  \\\ncount    2089.000000  2000.000000  2089.000000   1948.000000  1927.000000   \nunique           NaN          NaN          NaN           NaN          NaN   \ntop              NaN          NaN          NaN           NaN          NaN   \nfreq             NaN          NaN          NaN           NaN          NaN   \nmean     1932.249402     2.483000   128.919579     25.662731     0.867151   \nstd      1495.474485     1.305206   115.745014    975.065350     0.339500   \nmin       450.000000     0.000000    15.000000     -1.000000     0.000000   \n25%       950.000000     2.000000    65.000000      2.000000     1.000000   \n50%      1400.000000     2.000000    90.000000      3.000000     1.000000   \n75%      2500.000000     3.000000   147.000000      5.000000     1.000000   \nmax     16000.000000     8.000000  1250.000000  43039.000000     1.000000   \n\n           Elevator    Penthouse      Cottage       Duplex  Semidetached  \ncount   1956.000000  2089.000000  2089.000000  2089.000000   2089.000000  \nunique          NaN          NaN          NaN          NaN           NaN  \ntop             NaN          NaN          NaN          NaN           NaN  \nfreq            NaN          NaN          NaN          NaN           NaN  \nmean       0.880879     0.080900     0.042125     0.030637      0.013404  \nstd        0.324013     0.272747     0.200923     0.172373      0.115023  \nmin        0.000000     0.000000     0.000000     0.000000      0.000000  \n25%        1.000000     0.000000     0.000000     0.000000      0.000000  \n50%        1.000000     0.000000     0.000000     0.000000      0.000000  \n75%        1.000000     0.000000     0.000000     0.000000      0.000000  \nmax        1.000000     1.000000     1.000000     1.000000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>District</th>\n      <th>Address</th>\n      <th>Number</th>\n      <th>Area</th>\n      <th>Rent</th>\n      <th>Bedrooms</th>\n      <th>Sq.Mt</th>\n      <th>Floor</th>\n      <th>Outer</th>\n      <th>Elevator</th>\n      <th>Penthouse</th>\n      <th>Cottage</th>\n      <th>Duplex</th>\n      <th>Semidetached</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2089.000000</td>\n      <td>2089</td>\n      <td>2089</td>\n      <td>747</td>\n      <td>2085</td>\n      <td>2089.000000</td>\n      <td>2000.000000</td>\n      <td>2089.000000</td>\n      <td>1948.000000</td>\n      <td>1927.000000</td>\n      <td>1956.000000</td>\n      <td>2089.000000</td>\n      <td>2089.000000</td>\n      <td>2089.000000</td>\n      <td>2089.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>20</td>\n      <td>1336</td>\n      <td>137</td>\n      <td>140</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Salamanca</td>\n      <td>Piso en Recoletos</td>\n      <td>1</td>\n      <td>Recoletos</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>313</td>\n      <td>25</td>\n      <td>29</td>\n      <td>93</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1094.026807</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1932.249402</td>\n      <td>2.483000</td>\n      <td>128.919579</td>\n      <td>25.662731</td>\n      <td>0.867151</td>\n      <td>0.880879</td>\n      <td>0.080900</td>\n      <td>0.042125</td>\n      <td>0.030637</td>\n      <td>0.013404</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>630.612544</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1495.474485</td>\n      <td>1.305206</td>\n      <td>115.745014</td>\n      <td>975.065350</td>\n      <td>0.339500</td>\n      <td>0.324013</td>\n      <td>0.272747</td>\n      <td>0.200923</td>\n      <td>0.172373</td>\n      <td>0.115023</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>450.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>550.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>950.000000</td>\n      <td>2.000000</td>\n      <td>65.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1094.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1400.000000</td>\n      <td>2.000000</td>\n      <td>90.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1636.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2500.000000</td>\n      <td>3.000000</td>\n      <td>147.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2188.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16000.000000</td>\n      <td>8.000000</td>\n      <td>1250.000000</td>\n      <td>43039.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data manipulation\n",
    "1. Throw away the column \"Number\", \"Adress\". \"Id\"\n",
    "2. Throw away all columns with missing values.\n",
    "3. Replace Rent (target) with a binary variable, which is True when the rent is above (or equal) its median, and False otherwise\n",
    "4. Replace the types of Penthouse, Cottage, Duplex, Semidetached, Outer and Elevator to binary.\n",
    "5. Replace the type of Bedrooms, District and Area to categoricals (Note: Bedrooms should have values in the range 0..8, inclusive)\n",
    "6. Split data to 70% train and 30% val\n",
    "\n",
    "No operation to be done in-place.  the result of steps 1,2,3,4,5 should be data_prepared.  The result of step 6 should be data_train and data_test."
   ],
   "metadata": {
    "id": "HXKwAvoi7X-D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_prepared = data.drop(columns=[\"Number\", \"Address\", \"Id\"])\n",
    "data_prepared = data_prepared.dropna(axis=0)\n",
    "data_prepared[\"Rent\"] = (data_prepared[\"Rent\"] >= data_prepared[\"Rent\"].median())\n",
    "data_prepared[\"Penthouse\"] = data[\"Penthouse\"].astype(bool)\n",
    "data_prepared[\"Cottage\"] = data[\"Cottage\"].astype(bool)\n",
    "data_prepared[\"Duplex\"] = data[\"Duplex\"].astype(bool)\n",
    "data_prepared[\"Semidetached\"] = data[\"Semidetached\"].astype(bool)\n",
    "data_prepared[\"Outer\"] = data[\"Outer\"].astype(bool)\n",
    "data_prepared[\"Elevator\"] = data[\"Elevator\"].astype(bool)\n",
    "data_prepared[\"Bedrooms\"] = data[\"Bedrooms\"].astype(\"category\")\n",
    "data_prepared[\"District\"] = data[\"District\"].astype(\"category\")\n",
    "data_prepared[\"Area\"] = data[\"Area\"].astype(\"category\")\n",
    "data_train, data_test = train_test_split(data_prepared, train_size = 0.7)"
   ],
   "metadata": {
    "id": "eUzVT9XM7Q9S",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:14:56.344088300Z",
     "start_time": "2024-01-25T11:14:56.330680Z"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_prepared.dtypes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE1ZhTNt9-_K",
    "outputId": "a4335c34-a295-4d4b-b1d9-6f74d12180a7",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:15:01.245382500Z",
     "start_time": "2024-01-25T11:15:01.231585600Z"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "District        category\nArea            category\nRent                bool\nBedrooms        category\nSq.Mt              int64\nFloor            float64\nOuter               bool\nElevator            bool\nPenthouse           bool\nCottage             bool\nDuplex              bool\nSemidetached        bool\ndtype: object"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Categorical Naive Bayes\n",
    "Using sklearn's Categorical Naive Bayes we will run the algorithm only on the categorical variables.\n",
    "Note that sklearn's implementation only works with integer calues categoricals, so you will have to do ordinal encoding.\n",
    "\n",
    "Print the training and the test accuracy that you get.  Use the score() method of the Naive Bayes objet to compute the accuracy."
   ],
   "metadata": {
    "id": "OZeyMXtt64fS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ],
   "metadata": {
    "id": "pd3g1sAz67Yj",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:15:05.912081Z",
     "start_time": "2024-01-25T11:15:05.896209500Z"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# The parameter alpha is the Laplace smoothing parameter (default 1)\n",
    "cat_nb = CategoricalNB(alpha=1)"
   ],
   "metadata": {
    "id": "YQ77lmFF7Jsv",
    "ExecuteTime": {
     "end_time": "2024-01-25T11:15:11.739052800Z",
     "start_time": "2024-01-25T11:15:11.730029900Z"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Your code here: Extract the categorical features, and fit cat_nb.\n",
    "# Then compute the accuracy of the trained cat_nb on the training and on the\n",
    "# test set.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "categorical_columns = [\"District\", \"Area\", \"Bedrooms\"]\n",
    "X_train_categorical = data_train[categorical_columns]\n",
    "X_test_categorical = data_test[categorical_columns]\n",
    "\n",
    "all_data = pd.concat([X_train_categorical, X_test_categorical])\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "all_data_encoded = ordinal_encoder.fit_transform(all_data)\n",
    "\n",
    "X_train_encoded = all_data_encoded[:len(X_train_categorical)]\n",
    "X_test_encoded = all_data_encoded[len(X_train_categorical):]\n",
    "\n",
    "y_train = data_train['Rent']\n",
    "y_test = data_test['Rent']\n",
    "\n",
    "cat_nb = CategoricalNB(alpha=1)\n",
    "cat_nb.fit(X_train_encoded, y_train)\n",
    "\n",
    "train_accuracy = cat_nb.score(X_train_encoded, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "test_accuracy = cat_nb.score(X_test_encoded, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ],
   "metadata": {
    "id": "ymDbHfekX97s",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:01:20.619512700Z",
     "start_time": "2024-01-25T17:01:20.591023200Z"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.83\n",
      "Test Accuracy: 0.79\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gaussian Naive Bayes (for the numerical features)\n",
    "Train a Gaussian Baive Bayes classifier using the features \"Floor\"\n",
    "and \"Sq.Mt\" (the two remaining features).  Print the training and testing\n",
    "error."
   ],
   "metadata": {
    "id": "GXvpbu9NZenZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "metadata": {
    "id": "YOk8q90ZY8q4",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:02:01.282965600Z",
     "start_time": "2024-01-25T17:02:01.275868400Z"
    }
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gauss_nb = GaussianNB()"
   ],
   "metadata": {
    "id": "MiK1AA5HZj8h",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:02:03.376086800Z",
     "start_time": "2024-01-25T17:02:03.367873100Z"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Your code here\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_numeric = data_train[['Floor', 'Sq.Mt']]\n",
    "X_test_numeric = data_test[['Floor', 'Sq.Mt']]\n",
    "\n",
    "y_train = data_train['Rent']\n",
    "y_test = data_test['Rent']\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_numeric, y_train)\n",
    "\n",
    "y_train_pred = gnb.predict(X_train_numeric)\n",
    "\n",
    "y_test_pred = gnb.predict(X_test_numeric)\n",
    "\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Error: {train_error:.2f}\")\n",
    "print(f\"Testing Error: {test_error:.2f}\")"
   ],
   "metadata": {
    "id": "csznmZhFZrCj",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:04:15.349924Z",
     "start_time": "2024-01-25T17:04:15.330357600Z"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.20\n",
      "Testing Error: 0.19\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing with Logistic Regression\n",
    "Run logistic regression on the numerical features (Floor, Sq.Mt) and compare your result with GaussianNB.  \n",
    "Documentation for Logistic Regression:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "No need to regularize - you have enough data, and only two features.  Also no need to play with the implementation parameters for now.  Just use the usual\n",
    "\"fit\" and \"predict\" to train and to get a (hard) prediction.\n",
    "Did you get a better or a worse result compared to Gaussian NB?\n",
    "\n",
    "It is likely that Logistic Regression would give a better result, because Logistic Regression makes fewer assumptions on the data, while Niave Bayes makes strong assumptions.  It is folklore in the ML community though that Naive Bayes would be typically better than logistic regression on small datasets, and logistic regression better on large datasets.  \n",
    "\n",
    "Therefore, if you have enough data, as is the case here, logistic regression is probably better."
   ],
   "metadata": {
    "id": "19wDePT1UuWy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Your code here: fit the lr to the numerical features, compute accuracy for train, test\n",
    "lr.fit(X_train_numeric, y_train)\n",
    "\n",
    "y_train_pred_lr = lr.predict(X_train_numeric)\n",
    "\n",
    "y_test_pred_lr = lr.predict(X_test_numeric)\n",
    "\n",
    "train_error_lr = 1 - accuracy_score(y_train, y_train_pred_lr)\n",
    "test_error_lr = 1 - accuracy_score(y_test, y_test_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Training Error: {train_error_lr:.2f}\")\n",
    "print(f\"Testing Error: {test_error_lr:.2f}\")\n",
    "\n",
    "print(\"\\nComparison with Gaussian Naive Bayes:\")\n",
    "print(f\"Training Error (GaussianNB): {train_error:.2f}\")\n",
    "print(f\"Testing Error (GaussianNB): {test_error:.2f}\")"
   ],
   "metadata": {
    "id": "ny99sOIVaECc",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:07:24.078705700Z",
     "start_time": "2024-01-25T17:07:24.047580700Z"
    }
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Training Error: 0.17\n",
      "Testing Error: 0.19\n",
      "\n",
      "Comparison with Gaussian Naive Bayes:\n",
      "Training Error (GaussianNB): 0.20\n",
      "Testing Error (GaussianNB): 0.19\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining categorical and Gaussian NB\n",
    "Although sklearn does not offer this out of the box, it turns out not to be very difficult to combine the Gaussian and categorical NB outputs into one\n",
    "NB \"mixture\".  This method is described below.  It is not mandatoery to do it, and in case you want to do something easier, skip to \"Easier Solution\" below.\n",
    "\n",
    "\n",
    "#### Non-mandatory method (with theoretical justification)\n",
    "Remember that the Naive Bayes assumption is, that the\n",
    "features are conditionally independent.  This means that the numerical features are independent of the categorical features.  And this means that, conditioned on the label y, the likelihood of the features is the product of the likelihood of the categoricals and the likelihood of the numericals.  Luckily, sklearn gives us the log likelihoods, so we can just add them up to get the log of the product of the likelihoods.\n",
    "\n",
    "Given a dataset X of sample points, the method predict_joint_log_proba(X) of sklearn's NB returns for each sample point x in X and each class y, the joint log probability:\n",
    "\n",
    "log p(x,y) = log p(x|y) + log p(y)\n",
    "\n",
    "Applying predict_joint_log_proba for both the categorical and the gaussian NB's, we will get from the Categorical NB the expression log p(x_cat, y) for all the point x in X, where x_cat are the categorical features of x.  This also equals:\n",
    "\n",
    "(1)  log p(x_cat,y) = log p(x_cat|y) + log p(y)\n",
    "\n",
    "From Gaussian NB we get the expression log p(x_num, y), where x_num are the numerical features of x.  This also equals:\n",
    "\n",
    "(2) log p(x_num,y) = log p(x_num|y) + log p(y)\n",
    "\n",
    "The probabilities of the combined model (due to conditional independence of x_cat and x_num, by Naive Bayes assumption) are given by:\n",
    "\n",
    "log p(x,y) = log p(x_cat|y) + log p(x_num|y) + log p(y)\n",
    "\n",
    "Therefore, using (1) and (2):\n",
    "\n",
    "log p(x,y) = log p(x_cat, y) + log p(x_num, y) - log p(y)\n",
    "\n",
    "The expression log p(y) is given by the prior of y, which is close to 50%/50% (because the way we created a binary target from the Rent - using the median).  Therefore we will use p(y) = log(0.5) for both y=+1 and y=-1.  [Generally, you could get p(y) from the data, but we don't really need it here because it is pretty much known]\n",
    "\n",
    "Write a function predict_from_combined_NBs(X) which takes a set of samples (which would be either data_train or data_test) and returns (hard) predictions using the combined NB classifiers, as described above.  If you did it write, you should get accuracy which is better than both what you got for GaussianNB and CategorialNB.\n",
    "\n",
    "#### Easier Solution\n",
    "Use the CategoricalNB soft-prediction (predict_proba method, see Naive Bayes documentation for sklearn) to add a feature to GaussianNB.  This means that you have to retrain GaussianNB using the extra feature, given by the soft-prediction of CategoricalNB!  \\"
   ],
   "metadata": {
    "id": "9PNijhFvXEGO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Your code here (for one of the two methods above)"
   ],
   "metadata": {
    "id": "VoDC99Tcxod-"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cat_nb = CategoricalNB(alpha=1)\n",
    "cat_nb.fit(X_train_encoded, y_train)\n",
    "\n",
    "X_train_cat_prob = cat_nb.predict_proba(X_train_encoded)\n",
    "X_test_cat_prob = cat_nb.predict_proba(X_test_encoded)\n",
    "\n",
    "X_train_augmented = np.concatenate([X_train_numeric, X_train_cat_prob], axis=1)\n",
    "X_test_augmented = np.concatenate([X_test_numeric, X_test_cat_prob], axis=1)\n",
    "\n",
    "gnb_augmented = GaussianNB()\n",
    "gnb_augmented.fit(X_train_augmented, y_train)\n",
    "\n",
    "y_train_pred_gnb_augmented = gnb_augmented.predict(X_train_augmented)\n",
    "\n",
    "y_test_pred_gnb_augmented = gnb_augmented.predict(X_test_augmented)\n",
    "\n",
    "train_error_gnb_augmented = 1 - accuracy_score(y_train, y_train_pred_gnb_augmented)\n",
    "test_error_gnb_augmented = 1 - accuracy_score(y_test, y_test_pred_gnb_augmented)\n",
    "\n",
    "print(\"Gaussian Naive Bayes with Added Feature from CategoricalNB Soft Predictions:\")\n",
    "print(f\"Training Error: {train_error_gnb_augmented:.2f}\")\n",
    "print(f\"Testing Error: {test_error_gnb_augmented:.2f}\")"
   ],
   "metadata": {
    "id": "FpJQxj2604a9",
    "ExecuteTime": {
     "end_time": "2024-01-25T17:10:07.047374500Z",
     "start_time": "2024-01-25T17:10:07.009272100Z"
    }
   },
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes with Added Feature from CategoricalNB Soft Predictions:\n",
      "Training Error: 0.14\n",
      "Testing Error: 0.18\n"
     ]
    }
   ]
  }
 ]
}
